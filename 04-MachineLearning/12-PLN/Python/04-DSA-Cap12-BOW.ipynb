{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy - Machine Learning</font>\n",
    "\n",
    "# <font color='blue'>Capítulo 12 - Processamento de Linguagem Natural</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.8.2\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obs: Este é um material de bônus incluído neste curso. PyTorch é estudado em detalhes no curso <a href=\"https://www.datascienceacademy.com.br/course?courseid=deep-learning-frameworks\">Deep Learning Frameworks</a> e aplicado em PLN no curso <a href=\"https://www.datascienceacademy.com.br/course?courseid=processamento-de-linguagem-natural-e-reconhecimento-de-voz\">Processamento de Linguagem Natural</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Classificação de Idiomas de Sentenças com Bag of Words e PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/bow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# !pip install torch==1.5.0\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "#!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o PyTorch\n",
    "#!pip install -q -U torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n",
      "numpy     : 1.19.2\n",
      "matplotlib: 3.5.0\n",
      "torch     : 1.11.0\n",
      "pandas    : 1.3.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de treino\n",
    "dados_treino = [(\"Tenho vinte paginas de leitura\".lower().split(), \"Portuguese\"),\n",
    "                (\"I will visit the library\".lower().split(), \"English\"),\n",
    "                (\"I am reading a book\".lower().split(), \"English\"),\n",
    "                (\"This is my favourite chapter\".lower().split(), \"English\"),\n",
    "                (\"Estou na biblioteca lendo meu livro preferido\".lower().split(), \"Portuguese\"),\n",
    "                (\"Gosto de livros sobre viagens\".lower().split(), \"Portuguese\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['tenho', 'vinte', 'paginas', 'de', 'leitura'], 'Portuguese'),\n",
       " (['i', 'will', 'visit', 'the', 'library'], 'English'),\n",
       " (['i', 'am', 'reading', 'a', 'book'], 'English'),\n",
       " (['this', 'is', 'my', 'favourite', 'chapter'], 'English'),\n",
       " (['estou', 'na', 'biblioteca', 'lendo', 'meu', 'livro', 'preferido'],\n",
       "  'Portuguese'),\n",
       " (['gosto', 'de', 'livros', 'sobre', 'viagens'], 'Portuguese')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de teste\n",
    "dados_teste = [(\"Estou lendo\".lower().split(), \"Portuguese\"),\n",
    "               (\"This is not my favourite book\".lower().split(), \"English\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['estou', 'lendo'], 'Portuguese'),\n",
       " (['this', 'is', 'not', 'my', 'favourite', 'book'], 'English')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara o dicionário do vocabulário\n",
    "\n",
    "# Dicionário para o vocabulário\n",
    "dict_vocab = {}\n",
    "\n",
    "# Contadoor\n",
    "i = 0\n",
    "\n",
    "# Loop pelos dados de treino e teste\n",
    "for palavras, idiomas in dados_treino + dados_teste:\n",
    "    for palavra in palavras:\n",
    "        if palavra not in dict_vocab:\n",
    "            dict_vocab[palavra] = i\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tenho': 0, 'vinte': 1, 'paginas': 2, 'de': 3, 'leitura': 4, 'i': 5, 'will': 6, 'visit': 7, 'the': 8, 'library': 9, 'am': 10, 'reading': 11, 'a': 12, 'book': 13, 'this': 14, 'is': 15, 'my': 16, 'favourite': 17, 'chapter': 18, 'estou': 19, 'na': 20, 'biblioteca': 21, 'lendo': 22, 'meu': 23, 'livro': 24, 'preferido': 25, 'gosto': 26, 'livros': 27, 'sobre': 28, 'viagens': 29, 'not': 30}\n"
     ]
    }
   ],
   "source": [
    "# Visualiza o vocabulário\n",
    "print(dict_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho do corpus\n",
    "tamanho_corpus = len(dict_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tamanho_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de idiomas\n",
    "idiomas = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Índice para os idiomas\n",
    "label_index = {\"Portuguese\": 0, \"English\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construção do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para o modelo BOW de classificação\n",
    "class ModeloBOW(nn.Module):  \n",
    "\n",
    "    # Método construtor\n",
    "    def __init__(self, lista_idiomas, tamanho_do_corpus):\n",
    "        super(ModeloBOW, self).__init__()\n",
    "        self.linear = nn.Linear(tamanho_do_corpus, lista_idiomas)\n",
    "\n",
    "    # Feed Forward\n",
    "    def forward(self, bow_vec):\n",
    "        return F.log_softmax(self.linear(bow_vec), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar o vetor BOW necessário para o treinamento\n",
    "def cria_bow_vetor(sentence, word_index):\n",
    "    word_vec = torch.zeros(tamanho_corpus)\n",
    "    for word in sentence:\n",
    "        # Adicionar palavra ao dicionário e aumentar o tamanho corpus\n",
    "        word_vec[dict_vocab[word]] += 1\n",
    "    return word_vec.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar a variável target\n",
    "def cria_target(label, label_index):\n",
    "    return torch.LongTensor([label_index[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o modelo\n",
    "modelo = ModeloBOW(idiomas, tamanho_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de perda (loss)\n",
    "loss_function = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otimizador\n",
    "optimizer = optim.SGD(modelo.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , Loss: 1.0166406631469727\n",
      "Epoch:  11 , Loss: 0.0929742231965065\n",
      "Epoch:  21 , Loss: 0.04588890075683594\n",
      "Epoch:  31 , Loss: 0.030261052772402763\n",
      "Epoch:  41 , Loss: 0.022522488608956337\n",
      "Epoch:  51 , Loss: 0.017916858196258545\n",
      "Epoch:  61 , Loss: 0.01486651785671711\n",
      "Epoch:  71 , Loss: 0.012699330225586891\n",
      "Epoch:  81 , Loss: 0.011080989614129066\n",
      "Epoch:  91 , Loss: 0.00982685573399067\n"
     ]
    }
   ],
   "source": [
    "# Loop de treinamentoo\n",
    "for epoch in range(100):\n",
    "    \n",
    "    for sentence, label in dados_treino:\n",
    "\n",
    "        modelo.zero_grad()\n",
    "\n",
    "        bow_vec = cria_bow_vetor(sentence, dict_vocab)\n",
    "        target = cria_target(label, label_index)\n",
    "\n",
    "        log_probs = modelo(bow_vec)\n",
    "\n",
    "        loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: ', str(epoch+1),', Loss: ' + str(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsões e Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_news_words(sentence):\n",
    "    for word in sentence:\n",
    "        if dict_vocab.get(word) == None:\n",
    "            print(\"\\t adicionando:\", word)\n",
    "            dict_vocab[word] = len(dict_vocab)\n",
    "            print(dict_vocab)\n",
    "            tamanho_corpus = len(dict_vocab)\n",
    "            print(tamanho_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para previsões\n",
    "def faz_previsao(data):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sentence = data[0]\n",
    "        label = data[1]\n",
    "        validate_news_words(sentence)\n",
    "        bow_vec = cria_bow_vetor(sentence, dict_vocab)\n",
    "        log_probs = modelo(bow_vec)\n",
    "        print(sentence)\n",
    "        print('Probabilidade de ser o label: ' + label, 'é igual a: ',  np.exp(log_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estou', 'lendo']\n",
      "Probabilidade de ser o label: Portuguese é igual a:  tensor([[0.7613, 0.2387]])\n"
     ]
    }
   ],
   "source": [
    "# Previsão com a primeira sentença de teste\n",
    "faz_previsao(dados_teste[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['estou', 'lendo'], 'Portuguese')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_teste[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'not', 'my', 'favourite', 'book']\n",
      "Probabilidade de ser o label: English é igual a:  tensor([[0.0123, 0.9877]])\n"
     ]
    }
   ],
   "source": [
    "# Previsão com a segunda sentença de teste\n",
    "faz_previsao(dados_teste[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['this', 'is', 'not', 'my', 'favourite', 'book'], 'English')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_teste[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsões com Novas Frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nova frase\n",
    "novas_frases = [(\"Tenho livros sobre viagens\".lower().split(), \"Portuguese\"),\n",
    "                (\"Estou escrevendo\".lower().split(), \"Portuguese\"),\n",
    "                (\"Gosto de biblioteca\".lower().split(), \"Portuguese\"),\n",
    "                (\"Eu perdi o meu mouse\".lower().split(), \"Portuguese\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['tenho', 'livros', 'sobre', 'viagens'], 'Portuguese'),\n",
       " (['estou', 'escrevendo'], 'Portuguese'),\n",
       " (['gosto', 'de', 'biblioteca'], 'Portuguese'),\n",
       " (['eu', 'perdi', 'o', 'meu', 'mouse'], 'Portuguese')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novas_frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tenho', 'livros', 'sobre', 'viagens']\n",
      "Probabilidade de ser o label: Portuguese é igual a:  tensor([[0.9679, 0.0321]])\n"
     ]
    }
   ],
   "source": [
    "faz_previsao(novas_frases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t adicionando: escrevendo\n",
      "{'tenho': 0, 'vinte': 1, 'paginas': 2, 'de': 3, 'leitura': 4, 'i': 5, 'will': 6, 'visit': 7, 'the': 8, 'library': 9, 'am': 10, 'reading': 11, 'a': 12, 'book': 13, 'this': 14, 'is': 15, 'my': 16, 'favourite': 17, 'chapter': 18, 'estou': 19, 'na': 20, 'biblioteca': 21, 'lendo': 22, 'meu': 23, 'livro': 24, 'preferido': 25, 'gosto': 26, 'livros': 27, 'sobre': 28, 'viagens': 29, 'not': 30, 'escrevendo': 31}\n",
      "32\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 31 is out of bounds for dimension 0 with size 31",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfaz_previsao\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnovas_frases\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36mfaz_previsao\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      6\u001b[0m label \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m validate_news_words(sentence)\n\u001b[0;32m----> 8\u001b[0m bow_vec \u001b[38;5;241m=\u001b[39m \u001b[43mcria_bow_vetor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_vocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m modelo(bow_vec)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(sentence)\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mcria_bow_vetor\u001b[0;34m(sentence, word_index)\u001b[0m\n\u001b[1;32m      3\u001b[0m word_vec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(tamanho_corpus)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence:\n\u001b[0;32m----> 5\u001b[0m     word_vec[dict_vocab[word]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m word_vec\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 31 is out of bounds for dimension 0 with size 31"
     ]
    }
   ],
   "source": [
    "faz_previsao(novas_frases[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_previsao(novas_frases[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faz_previsao(novas_frases[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
