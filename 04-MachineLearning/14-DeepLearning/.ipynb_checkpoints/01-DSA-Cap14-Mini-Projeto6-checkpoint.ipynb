{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy - Machine Learning</font>\n",
    "\n",
    "# <font color='blue'>Capítulo 14</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Projeto 6\n",
    "\n",
    "## Classificação de Imagens com Deep Learning e PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/mini-projeto6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você tem 3 opções:\n",
    "\n",
    "- 1- Não tem GPU no seu computador? Executar este Jupyter Notebook normalmente, nesse caso com treinamento em CPU.\n",
    "\n",
    "\n",
    "- 2- Tem GPU no seu computador? Executar este Jupyter Notebook normalmente, nesse caso com treinamento em GPU.\n",
    "\n",
    "\n",
    "- 3- Não tem GPU no seu computador? Executar este Jupyter Notebook na nuvem, com o <a href=\"https://colab.research.google.com/\">Google Colab</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do Problema\n",
    "\n",
    "![title](imagens/CV.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando e Carregando os Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o PyTorch\n",
    "!pip install -q torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala o Torchvision\n",
    "!pip install -q torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a GPU\n",
    "\n",
    "http://pytorch.org/docs/stable/cuda.html\n",
    "\n",
    "https://developer.nvidia.com/cuda-zone\n",
    "\n",
    "Pode ser útil acelerar o tempo de treinamento usando uma GPU. CUDA é uma plataforma da Nvidia que permite usarmos as GPUs (Nvidia) para processamento paralelo). Os frameworks de Deep Learning dependem da plataforma CUDA para o processamento em GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar somente se a máquina tiver GPU e Plataforma CUDA instalada\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se a plataforma CUDA está disponível\n",
    "train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mensagem para o usuário\n",
    "if not train_on_gpu:\n",
    "    print('Plataforma CUDA não está disponível. O treinamento será realizado com a CPU ...')\n",
    "else:\n",
    "    print('Plataforma CUDA está disponível! O treinamento será realizado com a GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checando o Hardware Disponível no Servidor da DSA - CPU e GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista todos os dispositivos disponiveis\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se por acaso não aparecer para você todas as GPUs, reinstale o TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall tensorflow\n",
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Número Disponível de GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista o código de cada GPU\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Dataset\n",
    "\n",
    "http://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "O download pode demorar um minuto. Carregamos os dados de treinamento e teste, dividimos os dados de treinamento em um conjunto de treinamento e validação e, em seguida, criamos DataLoaders para cada um desses conjuntos de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset usado: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que converte os dados em um tensor normalizado\n",
    "transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomRotation(10),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dos dados de treino\n",
    "dados_treino = datasets.CIFAR10('dados', \n",
    "                                train = True,\n",
    "                                download = True, \n",
    "                                transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dos dados de teste\n",
    "dados_teste = datasets.CIFAR10('dados', \n",
    "                               train = False,\n",
    "                               download = True, \n",
    "                               transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de treino\n",
    "dados_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de teste\n",
    "dados_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de amostras de treino\n",
    "num_amostras_treino = len(dados_treino)\n",
    "num_amostras_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos um índice e o tornamos randômico\n",
    "indices = list(range(num_amostras_treino))\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentual dos dados de treino que usaremos no dataset de validação\n",
    "valid_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora fazemos o split para os dados de treino e validação\n",
    "split = int(np.floor(valid_size * num_amostras_treino))\n",
    "idx_treino, idx_valid = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos as amostras de treino\n",
    "amostras_treino = SubsetRandomSampler(idx_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos as amostras de validação\n",
    "amostras_valid = SubsetRandomSampler(idx_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora preparamos os data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de subprocessos para carregar os dados\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de amostras por batch\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader de dados de treino\n",
    "loader_treino = torch.utils.data.DataLoader(dados_treino, \n",
    "                                            batch_size = batch_size, \n",
    "                                            sampler = amostras_treino, \n",
    "                                            num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader de dados de validação\n",
    "loader_valid = torch.utils.data.DataLoader(dados_treino, \n",
    "                                           batch_size = batch_size, \n",
    "                                           sampler = amostras_valid, \n",
    "                                           num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader de dados de teste\n",
    "loader_teste = torch.utils.data.DataLoader(dados_teste, \n",
    "                                           batch_size = batch_size, \n",
    "                                           num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de classes das imagens\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para desnormalização das imagens\n",
    "def imshow(img):\n",
    "    \n",
    "    # Desfaz a normalização\n",
    "    img = img / 2 + 0.5  \n",
    "    \n",
    "    # Converte em tensor e imprime\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém um batch de dados de treino\n",
    "dataiter = iter(loader_treino)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte as imagens em formato NumPy\n",
    "images = images.numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de um batch de imagens de treino\n",
    "\n",
    "# Área de plotagem\n",
    "fig = plt.figure(figsize = (25, 4))\n",
    "\n",
    "# Loop e print\n",
    "for idx in np.arange(20):\n",
    "    \n",
    "    # Cria os subplots\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    \n",
    "    # Desfaz a normalização\n",
    "    # images[idx]\n",
    "    imshow(images[idx])\n",
    "    \n",
    "    # Coloca o título\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando Uma Imagem em Mais Detalhes\n",
    "\n",
    "Aqui, observamos os canais de cores normalizados de vermelho, verde e azul (RGB) como três imagens separadas com intensidade de tons de cinza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraímos os canais de cores\n",
    "rgb_img = np.squeeze(images[3])\n",
    "channels = ['Canal Vermelho (Red)', 'Canal Verde (Green)', 'Canal Azul (Blue)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop e print\n",
    "\n",
    "# Área de plotagem\n",
    "fig = plt.figure(figsize = (36, 36)) \n",
    "\n",
    "# Loop pelas imagens\n",
    "for idx in np.arange(rgb_img.shape[0]):\n",
    "    \n",
    "    # Subplot\n",
    "    ax = fig.add_subplot(1, 3, idx + 1)\n",
    "    \n",
    "    # Índice\n",
    "    img = rgb_img[idx]\n",
    "    \n",
    "    # Mostra a imagem em escala de cinza\n",
    "    ax.imshow(img, cmap = 'gray')\n",
    "    \n",
    "    # Título\n",
    "    ax.set_title(channels[idx])\n",
    "    \n",
    "    # Largura e altura da imagem\n",
    "    width, height = img.shape\n",
    "    \n",
    "    # Limite\n",
    "    thresh = img.max()/2.5\n",
    "    \n",
    "    # Loop\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
    "            ax.annotate(str(val), \n",
    "                        xy = (y,x), \n",
    "                        horizontalalignment = 'center', \n",
    "                        verticalalignment = 'center', \n",
    "                        size = 8,\n",
    "                        color = 'white' if img[x][y] < thresh else 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo a Arquitetura da Rede\n",
    "\n",
    "http://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "Vamos definir uma arquitetura CNN (Convolutional Neural Network). \n",
    "\n",
    "* [Camadas convolucionais](https://pytorch.org/docs/stable/nn.html#conv2d), podem ser consideradas como uma pilha de imagens filtradas.\n",
    "\n",
    "* [Camadas de Maxpool](https://pytorch.org/docs/stable/nn.html#maxpool2d), reduzem o tamanho x-y de uma entrada, mantendo apenas os pixels mais _ativos_ da camada anterior.\n",
    "\n",
    "* As camadas Linear + Dropout podem evitar sobreajuste e produzir uma saída de 10 dimensões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura do Modelo\n",
    "class ModeloCNN(nn.Module):\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self):\n",
    "        super(ModeloCNN, self).__init__()\n",
    "        \n",
    "        # Camada Convolucional de entrada \n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding = 1)\n",
    "        \n",
    "        # Camada Convolucional oculta \n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n",
    "        \n",
    "        # Camada Convolucional oculta \n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        \n",
    "        # Camada de Max Pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Camada Totalmente Conectada 1\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
    "        \n",
    "        # Camada Totalmente Conectada 2\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        \n",
    "        # Camada de Dropout (Regularização)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    # Método Forward\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Adiciona uma camada de ativação Relu para cada camada convolucional\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # Faz o \"achatamento\" da matriz resultante da convolução e cria um vetor\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        \n",
    "        # Adiciona uma camada de dropout para regularização\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Adiciona a 1ª camada oculta, com função de ativação relu\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Adiciona uma camada de dropout para regularização\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Adiciona a 2ª camada oculta (classificação feita pelo modelo)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o modelo\n",
    "modelo = ModeloCNN()\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movemos o modelo para a GPU se disponível\n",
    "if train_on_gpu:\n",
    "    modelo.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de Perda (Loss Function)\n",
    "\n",
    "http://pytorch.org/docs/stable/nn.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function como categorical cross-entropy\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimizador\n",
    "\n",
    "http://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetro\n",
    "taxa_aprendizado = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otimizador com SGD\n",
    "optimizer = optim.SGD(modelo.parameters(), lr = taxa_aprendizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "Lembre-se de observar como a perda em treinamento e validação diminui com o tempo; se a perda em validação aumentar, isso indica um possível sobreajuste (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de épocas para treinar o modelo\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiperparâmetro para controlar a mudança do erro em validação\n",
    "erro_valid_min = np.Inf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamos o modelo (a execução desta célula pode demorar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "\n",
    "    # Parâmetros para acompanhar o erro total em treinamento e validação\n",
    "    erro_treino = 0.0\n",
    "    erro_valid = 0.0\n",
    "    \n",
    "    # Inicia o treinamento do modelo\n",
    "    modelo.train()\n",
    "    \n",
    "    # Loop pelos batches de dados de treino\n",
    "    for batch_idx, (data, target) in enumerate(loader_treino):\n",
    "        \n",
    "        # Move os tensores para a GPU se disponível\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # Limpa os gradientes de todas as variáveis otimizadas\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward: calcula as saídas previstas\n",
    "        output = modelo(data)\n",
    "        \n",
    "        # Calcula o erro no batch\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward: calcula o gradiente da perda em relação aos parâmetros do modelo\n",
    "        loss.backward()\n",
    "        \n",
    "        # Realiza uma única etapa de otimização (atualização dos parâmetros)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Atualiza o erro total em treino\n",
    "        erro_treino += loss.item() * data.size(0)\n",
    "        \n",
    "    # Inicia a validação do modelo\n",
    "    modelo.eval()\n",
    "    \n",
    "    # Loop pelos batches de dados de validação\n",
    "    for batch_idx, (data, target) in enumerate(loader_valid):\n",
    "        \n",
    "        # Move os tensores para a GPU se disponível\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # Forward: calcula as saídas previstas\n",
    "        output = modelo(data)\n",
    "        \n",
    "        # Calcula o erro no batch\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Atualiza o erro total de validação\n",
    "        erro_valid += loss.item() * data.size(0)\n",
    "    \n",
    "    # Calcula o erro médio\n",
    "    erro_treino = erro_treino / len(loader_treino.dataset)\n",
    "    erro_valid = erro_valid / len(loader_valid.dataset)\n",
    "        \n",
    "    # Print\n",
    "    print('\\nEpoch: {} \\tErro em Treinamento: {:.6f} \\tErro em Validação: {:.6f}'.format(epoch, \n",
    "                                                                                         erro_treino, \n",
    "                                                                                         erro_valid))\n",
    "    \n",
    "    # Salva o modelo sempre que a perda em validação diminuir\n",
    "    if erro_valid <= erro_valid_min:\n",
    "        print('Erro em Validação foi Reduzido ({:.6f} --> {:.6f}). Salvando o modelo...'.format(erro_valid_min,\n",
    "                                                                                                 erro_valid))\n",
    "        torch.save(modelo.state_dict(), 'modelos/modelo_final.pt')\n",
    "        erro_valid_min = erro_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrega o Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o modelo\n",
    "modelo.load_state_dict(torch.load('modelos/modelo_final.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando e Avaliando o Modelo Final\n",
    "\n",
    "Testamos o modelo treinado em dados nunca vistos anteriormente! Um resultado \"bom\" será uma CNN que obtenha cerca de 70% (ou mais, tente o seu melhor!) de precisão nas imagens de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erro em teste\n",
    "erro_teste = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controle de acertos do modelo\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicia a avaliação do modelo\n",
    "modelo.eval()\n",
    "\n",
    "# Loop pelos batches de dados de teste\n",
    "for batch_idx, (data, target) in enumerate(loader_teste):\n",
    "    \n",
    "    # Move os tensores para GPU se disponível\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    # Forward\n",
    "    output = modelo(data)\n",
    "    \n",
    "    # Calcula o erro\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    # Atualiza o erro em teste\n",
    "    erro_teste += loss.item() * data.size(0)\n",
    "    \n",
    "    # Converte probabilidades de saída em classe prevista\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    \n",
    "    # Compara as previsões com o rótulo verdadeiro\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    \n",
    "    # Calcula a precisão do teste para cada classe\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# Erro médio em teste\n",
    "erro_teste = erro_teste / len(loader_teste.dataset)\n",
    "print('\\nErro em Teste: {:.6f}\\n'.format(erro_teste))\n",
    "\n",
    "# Calcula a acurácia para cada classe\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Acurácia em Teste da classe %5s: %2d%% (%2d/%2d)' % (classes[i], \n",
    "                                                             100 * class_correct[i] / class_total[i],\n",
    "                                                             np.sum(class_correct[i]), \n",
    "                                                             np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Acurácia em Teste de %5s:)' % (classes[i]))\n",
    "\n",
    "# Calcula a acurácia total\n",
    "print('\\nAcurácia em Teste (Total): %2d%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total),\n",
    "                                                        np.sum(class_correct), \n",
    "                                                        np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsões com o Modelo Treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém um batch de dados de teste\n",
    "dataiter = iter(loader_teste)\n",
    "images, labels = dataiter.next()\n",
    "images.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move as imagens para a GPU se disponível\n",
    "if train_on_gpu:\n",
    "    images = images.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz as previsões com o modelo treinado\n",
    "output = modelo(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte probabilidades de saída em classe prevista\n",
    "_, preds_tensor = torch.max(output, 1)\n",
    "preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot das previsões\n",
    "fig = plt.figure(figsize = (25, 4))\n",
    "print(\"\\nEntre parênteses a classe real. Vermelho indica erro do modelo.\\n\")\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx].cpu())\n",
    "    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]), \n",
    "                 color = (\"green\" if preds[idx] == labels[idx].item() else \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning é o estado da arte em sistemas de Inteligência Artificial nos dias de hoje!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
